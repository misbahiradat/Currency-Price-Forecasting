{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Author @ Misbah Iradat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts/')\n",
    "\n",
    "from tvDatafeed import TvDatafeed, Interval\n",
    "from credential import tradingview as settings\n",
    "\n",
    "username = settings['username']\n",
    "password = settings['password']\n",
    "\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "        data.reset_index(inplace=True)\n",
    "        result[symbol] = data\n",
    "    return result\n",
    "\n",
    "# Create an instance of TvDatafeed class\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "\n",
    "# Access individual dataframes\n",
    "gold_data = historical_data['XAUUSD']\n",
    "dollarIndex_data = historical_data['DXY']\n",
    "oil_data = historical_data['USOIL']\n",
    "interestrate_data = historical_data['USINTR']\n",
    "SP500 = historical_data['SPX500USD']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TvDatafeed(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "        data.reset_index(inplace=True)\n",
    "        result[symbol] = data\n",
    "    return result\n",
    "\n",
    "# Create an instance of TvDatafeed class\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "\n",
    "# Access individual dataframes\n",
    "gold_data = historical_data['XAUUSD']\n",
    "dollarIndex_data = historical_data['DXY']\n",
    "oil_data = historical_data['USOIL']\n",
    "interestrate_data = historical_data['USINTR']\n",
    "SP500 = historical_data['SPX500USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index\n",
    "gold_data = tv.get_hist(symbol='XAUUSD',exchange='OANDA',interval=Interval.in_daily,n_bars=10000)\n",
    "\n",
    "# futures continuous contract\n",
    "#nifty_futures_data = tv.get_hist(symbol='NIFTY',exchange='NSE',interval=Interval.in_1_hour,n_bars=1000,fut_contract=1)\n",
    "\n",
    "# crudeoil\n",
    "#crudeoil_data = tv.get_hist(symbol='CRUDEOIL',exchange='MCX',interval=Interval.in_1_hour,n_bars=5000,fut_contract=1)\n",
    "\n",
    "# downloading data for extended market hours\n",
    "#extended_price_data = tv.get_hist(symbol=\"EICHERMOT\",exchange=\"NSE\",interval=Interval.in_1_hour,n_bars=500, extended_session=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_data = gold_data.reset_index()\n",
    "gold_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollarIndex_data = tv.get_hist(symbol='DXY',exchange='TVC',interval=Interval.in_daily,n_bars=10000)\n",
    "dollarIndex_data.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollarIndex_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil_data = tv.get_hist(symbol='USOIL',exchange='TVC',interval=Interval.in_daily,n_bars=10000)\n",
    "oil_data.reset_index(inplace = True)\n",
    "oil_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestrate_data = tv.get_hist(symbol='USINTR',exchange='ECONOMICS',interval=Interval.in_daily,n_bars=10000)\n",
    "interestrate_data.reset_index(inplace = True)\n",
    "interestrate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500 = tv.get_hist(symbol='SPX500USD',exchange = 'OANDA',interval=Interval.in_daily,n_bars=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500.reset_index(inplace = True)\n",
    "SP500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import logging\n",
    "from sqlalchemy import Table, Column, Integer, Date, String, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy import insert\n",
    "# local files\n",
    "from session import *\n",
    "from datetime import datetime, date \n",
    "from credential import postgresql as settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging for the program\n",
    "logging.basicConfig(filename='tradingview_data_extraction.log', level=logging.DEBUG)\n",
    "logging.info(\"Program started at {}\".format(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sessions():\n",
    "    \"\"\"\n",
    "    Function to create the SQLAlchemy engine and session\n",
    "    Returns:\n",
    "        session object\n",
    "    \"\"\"\n",
    "    engine = get_engine_from_settings()\n",
    "    DynamicBase.metadata.create_all(bind=engine)\n",
    "    session = get_session()\n",
    "    return session\n",
    "\n",
    "# datetime\tsymbol\topen\thigh\tlow\tclose\tvolume\n",
    "def create_table(table_name, Base):\n",
    "    \"\"\"\n",
    "    Function to create table structure using SQLAlchemy ORM\n",
    "    Args:\n",
    "        table_name : name of the table to be created\n",
    "        Base       : SQLAlchemy Base object\n",
    "        engine     : SQLAlchemy engine object\n",
    "    Returns:\n",
    "        User       : SQLAlchemy ORM Class for the table\n",
    "    \"\"\"\n",
    "    \n",
    "    engine = get_engine_from_settings()\n",
    "    #DynamicBase = declarative_base(class_registry=dict())\n",
    "    class User(DynamicBase):\n",
    "            __tablename__ = table_name\n",
    "            id = Column(Integer, primary_key=True, autoincrement=True)\n",
    "            datetime = Column(Date) #nullable=False\n",
    "            open = Column(Float)\n",
    "            high = Column(Float)\n",
    "            low = Column(Float)\n",
    "            close = Column(Float)\n",
    "            volume = Column(Float)\n",
    "        \n",
    "    inspector = inspect(engine)\n",
    "    #if engine.has_table(table_name):\n",
    "    if inspector.has_table(table_name):\n",
    "        # if table exists, overwrite it\n",
    "        User.__table__.drop(engine)\n",
    "        User.__table__.create(engine)\n",
    "    else:\n",
    "        # if table does not exist, create it\n",
    "        Base.metadata.create_all(engine)\n",
    "        \n",
    "    return User\n",
    "\n",
    "def get_historical_data(tv, symbol_exchange_dict, interval, n_bars):\n",
    "    result = {}\n",
    "    for symbol, exchange in symbol_exchange_dict.items():\n",
    "        if not symbol == 'USCCPI':\n",
    "            data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars)\n",
    "            data.reset_index(inplace=True)\n",
    "            result[symbol] = data\n",
    "        else:\n",
    "            data = tv.get_hist(symbol=symbol, exchange=exchange,n_bars=500)\n",
    "            data.reset_index(inplace=True)\n",
    "            result[symbol] = data\n",
    "\n",
    "    return result\n",
    "\n",
    "def extract_load_data_to_postgres_db(Base,currency_symbol,historical_data):\n",
    "\n",
    "    name = currency_symbol.lower()+'_'+'data'\n",
    "    table_name = name\n",
    "    # Create SQLAlchemy Base object and User class using the create_table function\n",
    "    #Base = declarative_base()\n",
    "    User = create_table(table_name, Base)\n",
    "    # Create a SQLAlchemy session\n",
    "    session = Sessions()\n",
    "\n",
    "    # Log the start of data insertion into the database\n",
    "    logging.info(\"Start inserting data into {}\".format(table_name))\n",
    "    # Insert the data into the database using the bulk_insert_mappings method\n",
    "    #session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    # Commit the transaction to save the changes to the database\n",
    "    session.commit()\n",
    "    # Log the completion of data insertion and the successful completion of the program\n",
    "    logging.info(\"Data insertion completed at {}\".format(datetime.now()))\n",
    "    logging.info(\"Program completed successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "def get_latest_date(session, table_name):\n",
    "    # Define your SQL query to select the latest date from the table\n",
    "    sql_query = f\"SELECT max(datetime) FROM {table_name} LIMIT 5\"\n",
    "    #max(datetime)\n",
    "    # Execute the query and fetch the result\n",
    "    result = session.connection().execute(sql_query)\n",
    "    \n",
    "    # Fetch the first row (which contains the latest date)\n",
    "    latest_date = result.fetchone()[0]\n",
    "\n",
    "    #Check if the latest_date is not None, and then format and print it\n",
    "    if latest_date:\n",
    "        formatted_date = latest_date.strftime('%Y-%m-%d')\n",
    "        return formatted_date\n",
    "    else:\n",
    "        return (\"No data found in the table.\")\n",
    "    \n",
    "\n",
    "# Function to check if a table exists in the database\n",
    "def table_exists(session, table_name):\n",
    "    return session.connection().execute(\n",
    "        f\"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_name = '{table_name}')\"\n",
    "    ).scalar()\n",
    "\n",
    "\n",
    "def load_data_to_postgres_db(Base,currency_symbol,historical_data, session):\n",
    "    \n",
    "    name = currency_symbol.lower()+'_'+'data'\n",
    "    table_name = name\n",
    "    # Create SQLAlchemy Base object and User class using the create_table function\n",
    "    User = create_table(table_name, Base)\n",
    "    # Log the start of data insertion into the database\n",
    "    logging.info(\"Start inserting data into {}\".format(table_name))\n",
    "    # Insert the data into the database using the bulk_insert_mappings method\n",
    "    session.bulk_insert_mappings(User,historical_data.to_dict(orient='records'))\n",
    "    # Commit the transaction to save the changes to the database\n",
    "    session.commit()\n",
    "    # Log the completion of data insertion and the successful completion of the program\n",
    "    logging.info(\"Data insertion completed at {}\".format(datetime.now()))\n",
    "    logging.info(\"Program completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DynamicBase = declarative_base()\n",
    "\n",
    "username = '***********'\n",
    "password = '***********'\n",
    "tv = TvDatafeed(username, password)\n",
    "\n",
    "\n",
    "# Define symbol and exchange dictionary\n",
    "symbol_exchange_dict = {\n",
    "    'XAUUSD': 'OANDA',\n",
    "    'DXY': 'TVC',\n",
    "    'USOIL': 'TVC',\n",
    "    'USINTR': 'ECONOMICS',\n",
    "    'USCCPI': 'ECONOMICS',\n",
    "    'SPX500USD': 'OANDA'\n",
    "}\n",
    "\n",
    "# Get historical data for symbols and exchanges in the dictionary\n",
    "#historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_5760\\3431696096.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'datetime'] = data['datetime'].dt.date\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_5760\\3431696096.py:52: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, 'datetime'] = data['datetime'].dt.date\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_5760\\3431696096.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.loc[:, 'datetime'] = data['datetime'].dt.date\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_5760\\3431696096.py:52: FutureWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
      "  data.loc[:, 'datetime'] = data['datetime'].dt.date\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def process_historical_data(tv, symbol_exchange_dict, settings):\n",
    "    \"\"\"\n",
    "    Process historical data for multiple symbols and store it in a PostgreSQL database.\n",
    "\n",
    "    Args:\n",
    "        tv: TradingView object or module for fetching data.\n",
    "        symbol_exchange_dict (Dict[str, str]): A dictionary mapping symbols to exchanges.\n",
    "        settings (dict): A dictionary containing PostgreSQL database connection settings.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    session = Sessions()\n",
    "    # initializing the dictionary\n",
    "    historical_data = {}\n",
    "    new_historical_data = {}\n",
    "    # Iterate over the dictionary items\n",
    "    for symbol in symbol_exchange_dict.keys():\n",
    "        symbol_name = symbol\n",
    "        # creating table name\n",
    "        table_name = symbol_name.lower() + '_data'\n",
    "        # checking if table exists or not!\n",
    "        if not table_exists(session, table_name):\n",
    "            historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=10000)\n",
    "        else:\n",
    "            # if table exists, then we extract the last updated data and extract the date!\n",
    "            latest_date = get_latest_date(session, table_name)\n",
    "            # converting the date to the correct format!\n",
    "            latest_date = pd.to_datetime(latest_date)\n",
    "            # getting the last 100 day data!\n",
    "            new_historical_data = get_historical_data(tv, symbol_exchange_dict, interval=Interval.in_daily, n_bars=100)\n",
    "\n",
    "    if len(historical_data) > 0:\n",
    "        for symbol, data in historical_data.items():\n",
    "            symbol_name, symbol_data = symbol, data\n",
    "            # loading the data to the postgres database!\n",
    "            load_data_to_postgres_db(DynamicBase ,symbol_name,symbol_data, session)\n",
    "            logging.info(f\"Loaded historical data for {symbol_name} into the database.\")\n",
    "    else:\n",
    "        for symbol, data in new_historical_data.items():\n",
    "            symbol_name, symbol_data = symbol, data\n",
    "            table_name = symbol_name.lower() + '_data'\n",
    "            data = symbol_data.loc[symbol_data['datetime'].dt.date > latest_date.date()]\n",
    "            if 'index' in data.columns:\n",
    "                data = data.drop(columns=['index'])\n",
    "            data.loc[:, 'datetime'] = data['datetime'].dt.date\n",
    "            data = data.drop(columns=['symbol'])\n",
    "            # updating the table with new data!\n",
    "            data.to_sql(table_name, con= get_engine(settings['pguser'], \n",
    "                            settings['pgpass'], \n",
    "                            settings['host'], \n",
    "                            settings['port'], \n",
    "                            settings['pgdb']), if_exists='append', index=False)\n",
    "            logging.info(f\"Appended new historical data for {symbol_name} into the database.\")\n",
    "\n",
    "process_historical_data(tv, symbol_exchange_dict, settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = tv.get_hist(symbol='USCCPI', exchange='ECONOMICS', n_bars=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b90cab7ea642421f44636989edaf96d86cb1abe354b45ce6eed3b362842c2584"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
